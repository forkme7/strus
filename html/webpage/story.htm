<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 2.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
	<link rel="icon" type="image/ico" href="images/strus.ico" />
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="description" content="Story of strus, a collection of C++ libraries for building a full-text search engine." />
	<meta name="keywords" content="fulltext search engine C++" />
	<meta name="author" content="Patrick Frey <patrickpfrey (a) yahoo (dt) com" />
	<link rel="stylesheet" type="text/css" href="text-profile.css" title="Text Profile" media="all" />
	<title>Strus</title>
</head>

<body>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-63809026-4', 'auto');
  ga('send', 'pageview');
</script>
<div id="wrap">
	<div id="content">
		<h2>Why to build yet another search engine</h2>
		<h3>Personal motivation</h3>
		<p>The project <i>strus</i> started just out of frustration. I was working on a project
		that was doomed from the beginning for two years. After realising that it had to fail,
		I had to focus on finding a new job. Unfortunately this proved to be more difficult
		than I thought. I had to do something to keep myself spinning and I wanted to do
		something in a topic that I knew by heart. I was working for ten years in a company
		providing services for information retrieval and also implementing
		the core of the search engine for these services. So I knew what it was about and the
		problems I had to face. In September 2014 I started the project strus.
		</p>

		<h3>What is strus</h3>
		<p>Strus is a set of components (libraries, programs and language bindings)
		to build the core of a scalable full text search engine. It aims to cover
		classical IR as well as structured search for arbitrary complex expressions 
		on the boolean algebra of sets of term occurrencies (d,p) where d references a 
		document and p a discrete position number. Besides matching of expressions,
		strus also provides a mechanism to attach variables on subexpression matches
		than can be referenced in the presentation of the query result.</p>

		<h3>What distiguishes strus from other fulltext search engines</h3>
		<h4>Outsourcing the data storage</h4>
		<p>Strus can be build uppon any modern NOSQL key/value database that has
		an <a href="http://en.wikipedia.org/wiki/Upper_and_lower_bounds">upperbound seek</a>
		to implement its data storage.
		This reduces the complexity of the problem (the strus core with storage and query
		evaluation has about 32000 lines of code). Alternative implementations for the
		database can be provided by experts on the topic.</p>
		<h4>Modelling of structured queries</h4>
		<p>All open source search engines I know (e.g. Lucene,Xapian,Sphinx) express
		multi term expressions as subqueries. Strus implements expressions as operations
		in the boolean algebra of sets of pairs of document number and position in the document.
		Figuratively speaking: In classial open source search engines, a sequence of words
		<i>(A,B)</i> is a subquery of type sequence. In strus, a sequence of words is a set
		of occurrencies: The intersection of the occurrencies of <i>A</i>
		with the predecessor set of occurrencies of <i>B</i>. Results of expressions can be
		recombined in other expressions. <br/>
		You can extend strus by writing your own set join operators.
		An example that illustrates the capabilities of strus in expressing structures
		is the built-in operator <b>struct_within</b>: Get the minimal position element of each
		range (of a maximum size) where all input elements (arguments 2..N) occurr and that 
		is not overlapping with a structure element (argument 1). With this operator
		you can for example search for terms inside a range in the same sentence (the end of sentence
		marker serves as delimiting structure element here).<br/>
		Another advantage of this model is that you don't need query rewriting for 
		optimization, because in pure set operations implemented as merge of
		iterators with an efficient skip to the upperbound, the smaller set is dominating
		and the number of disk accesses is minimal.
		</p>
		<h4>Information extraction</h4>
		<p>In strus the result of the set operations needed to model expressions are
		implemented as iterators. The advantage of this model is not only that you
		do not need memory for storing intermediate results. You also do not need
		to care about what information to collect for an intermediate result. 
		As consequence all information about a match is available in the moment you
		inspect the match.
		A weighting function or a summarizer can access to positions of all 
		subexpression matches without expensive introspection.
		This empowers summarization to collect information that is part of a match
		or close to a match. Hence you can implement powerful information extraction
		for feature selection or feature extraction. If you have the resources
		to do strong NLP for normalizing your documents, you could even imagine
		to implement a system for query answering with strus.</p>

		<h2>Introducing the components of strus</h2>
		<p>
		This section introduces the core components strus.
		</p>
		<h3>Key/value store database</h3>
		<p>A key/value store database stores blocks of data for fast retrieval by their key.
		The database is separated as own component to allow competitive solutions
		for various architectures with different requirements implemented by experts
		for this topic. The key/value store database has to implement an upper bound
		seek on keys to support fast merging operations needed by the logical storage.
		Currently there exists an implementation based on LevelDB
		(In fact, LevelDB was the main stimulus for me to write a search engine.
		I looked at it and noticed: "<i>Heureka ! It has an upper bound seek. With this
		I can write a search engine !</i>").
		</p>
		<h3>Storage</h3>
		<p> The storage provides interfaces to define the units to store
		for retrieval and presentation of the search result. It allows you to
		define documents as numbered lists of atomic terms, content, attributes
		and meta data. For every document you can define user rights that restrict 
		access to a document to defined users. The storage groups these 
		definitions into blocks and tables stored for fast access in underlying 
		the key/value store database.
		</p>
		<h3>Query evaluation</h3>
		<p>The query evaluation combines the occurrencies of search terms according 
		to a given query to higher level expressions, ranks a set of selected documents
		according some defined weighting schemes and returns
		a list of documents with named attributes as result.
		Query evaluation is defined with the help of functions of two different types:</p>
		<h4>Weighting</h4>
		<p>Weighting accumulates a value as the weight of a document based on
		a retrieval scheme (e.g. BM25, tf-idf, proximity weighting, etc.).
		and the occurrencies of expressions in this document.
		</p>
		<h4>Summarization</h4>
		<p>Summarization extracts content elements, attributes or meta data from a
		matching document. As result summarizers return a set of weighted key
		value pairs for the presentation of the result. Summarization can be
		used for showing properties of the result to a user as well as for
		exraction of data for feature selection for another iteration of
		query evaluation in the background
		(<a href="http://en.wikipedia.org/wiki/Relevance_feedback">relevance feedback</a>).
		</p>
		<h2>Associated components of strus</h2>
		<p>For feeding a search engine there are some components needed that are not part
		of the core.
		<h3>Analyzer</h3>
		<p> The analyzer (also called indexer in other information retrieval engines)
			exists as a project, but it is not interlinked
			in an intrusive way with the strus core. The strusAnalyzer provides
			segmentation, tokenization and normalization to get the atomic terms
			to insert into the storage and to tokenize and normalize phrases of
			the query accordingly. The analyzer uses the following components
			to do its job:
		</p>
		<h4>Segmenter</h4>
		<p>The segmented splits a document of a certain format (XML,JSON,etc.) into content 
		chunks defined by selection expressions.
		Currently there exists only an implementation for XML based on the <a href="textwolf.net">textwolf</a>
		library using <a href="http://en.wikipedia.org/wiki/XPath#Abbreviated_syntax">abbreviated syntax of XPath</a>
		as selection language.
		</p>
		<h4>Tokenizer</h4>
		<p>The tokenizer splits a segment or alternatively the join of all segments 
		of a certain type into tokens. The tokens a referencing elements in the 
		segments without modification.
		</p>
		<h4>Normalizer</h4>
		<p>The normalizer maps a token to a term to be inserted into the storage.
		</p>
		<h2>Expandability of strus</h2>
		<p>Strus offers various interfaces to hook in. The project strusModule provides a
		mechanism to load functions extending capabilities of the storage or the analyzer
		of strus.
		<h3>strus core</h3>
		<p>You can extend the strus core with own dynamically loadable modules with
		functions written in C++:
		<ol>
		<h4>Iterator join operators</h4>
		<p>You can define your own functions that create an iterator on postings representing 
		the result of an n-ary join of iterators on postings.</p>
		<h4>Weighting functions</h4>
		<p>You can define your own document weighting functions used for ranking.</p>
		<h4>Summarizers</h4>
		<p>You can define your own summarization functions used for attributing the results.</p>
		<h3>strus analyzer</h3>
		<p>You can extend the strus analyzer with own dynamically loadable modules with
		functions written in C++:
		<ol>
		<h4>Segmenters</h4>
		<p>You can define your own segmenters for the document formats you need to process.</p>
		<h4>Tokenizer</h4>
		<p>You can define your own tokenizers splitting the document segments into tokens.</p>
		<h4>Normalizer</h4>
		<p>You can define your own normalizer functions to produce the retrievable items from 
		the document tokens for the storage and the query.</p>

		<h2>What is still missing in strus</h2>
		<h3>Documentation</h3>
		<p>The documentation of strus and its associated components is still poor. I am currently
		working hard on it every day.</p>

		<h3>Orchestration of a distributed index</h3>
		<p>The ability of distributing the search index and running <i>strus</i>
		as server nodes in a cluster without too much configuration and 
		administration effort is crucial for implementing a competitive search. <br/>
		<i>Strus</i> has interfaces to populate and receive statistics, that have to be shared
		in order to make ranking weights of different search engine nodes comparable. 
		<i>Strus</i> is built to take these statistics into account for ranking. 
		<i>strus</i> also has the interfaces to populate its statistics after startup 
		and all changes in its index during runtime.<br/>
		But the messaging to exchange this data and the orchestration
		of its nodes is not implemented yet.
		</p>

		<h2>What is not part of strus</h2>
		<p>Several parts are not a subject for strus. 
		Here follows a list of parts you may miss and have to find elsewhere.
		</p>
		<h3>Crawler</h3>
		<p> A crawler (also called robot) that searches for documents in the the internet 
		or an intranet, extracts and possibly transforms the content the ACLs for user rights <b>is not</b>
		part of strus. There exist sophisticated solutions for different classes of document
		collections.
		</p>
	</div>
</div>
</body>
</html>

